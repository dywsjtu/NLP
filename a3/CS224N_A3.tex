\documentclass{article}
\usepackage[utf8]{inputenc}

\title{CS224N_A3}
\author{dywsjtuji }
\date{July 2019}

\begin{document}

\maketitle

\section{Machine Learning & Neural Networks}

\textbf{(a)}\\
\textbf{(i)}\\
The momentum increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. By using m, we can gain faster convergence and reduced oscillation
\\
\textbf{(ii)}\\
Weights that receive high gradients will have their effective learning rate reduced and Weights that receive small / infrequent updates will have effective learning rate increased\\
\textbf{(b)}\\
\textbf{(i)}\\
 1/${p_{drop}}$\\
\textbf{(ii)}\\
At test time all neurons see all their inputs, so we want the outputs of neurons at test time to be identical to their expected outputs at training time
\end{document}
